\subsection{Common Subexpression Elimination}

Current code generation is based on SymPy \texttt{cse} function, which identifies the common sub-expressions and stores them temporary variables(i.e. \texttt{DENDRO\_}). 

Due to the complexity of the GR expressions, for some computation terms, we overflow the cache. For example, assume we have only two 3 cache lines and assuming that \texttt{a} \& \texttt{b} will fill the cahce, wthich result in a single cache miss for every iteration of the loop. 
\begin{lstlisting}[style=CStyle]
n=1000000;
for(i=0;i<n;i++)
      b_rhs[i]=a[i]+b[i]+c[i]+d[i];
\end{lstlisting}

But we can re-write the code such that, 
\begin{lstlisting}[style=CStyle]
n=1000000;
// pass 1
for(i=0;i<n;i++)
      b_rhs[i]=a[i]+b[i];
//pass 2
for(i=0;i<n;i++)
     b_rhs[i]+=(c[i]+d[i])
\end{lstlisting}

which has better cache performance hence after runtimes (i.e. experimentally this is 300 times faster where $n~=70,000$). 

\textbf{Note:} You can use the SymPy \texttt{dotprint} to generate \texttt{graphviz} compatible output computational graph for each expression. 

\subsection{Improving cache performance}

The next stage of the optimization is to re-write the \texttt{cse} generated functions, in stages such that it will improve the cache performance. 

\begin{itemize}
\item \textbf{Task 1 (Greedy approach) :}  By traversing the \texttt{cse} trees, figure out number of different variable acesses needed to compute a given temporary variable \texttt{DENDRO\_i} and if it hits a given threshold $\eta$ change it to a computed var (i.e. staged variable), and perform this recursively. 
\end{itemize}


